#!/usr/bin/perl
use strict;
use 5.010;
use Time::HiRes qw(time);
use EV;
use AnyEvent::Redis;
use IO::AIO qw(mmap aio_readahead);
use re::engine::RE2;
use JSON;
use Config::GitLike;

my $config = Config::GitLike->new(confname => "cpangrep")->load_file("etc/config");
my $dir = $config->{"location.slabs"};

my $c = $config->{"matcher.concurrency"} || 8;

for(1 .. $c) {
  my $pid = fork;
  if($pid) {
    if($_ == $c) { exit }
    next;
  } else {
    last;
  }
}

my $redis = AnyEvent::Redis->new;

sub open_cached {
  my($file) = @_;
  state %cache;

  open $cache{$file}, "<", $file or die "$file: $!" unless $cache{$file};
  return $cache{$file};
}

sub do_match {
  my($re, $max, $channel, $process) = @_;

  my $matches = 0;

  $re = qr/$re/m;

  my $i = 0;
  my $fh_next = open_cached($dir . "/" . $process->[$i++]);

  for my $file(@$process) {
    my $fh = $fh_next;
    mmap my $pm, -s $fh, IO::AIO::PROT_READ, IO::AIO::MAP_SHARED, $fh or die $!;

    if(my $next = $process->[$i++]) {
      $fh_next = open_cached($dir . "/" . $next);
      # On machines with spare IO bandwidth this seemed to help, however I'm now
      # running on VMs and this seems less of a help.
      #aio_readahead $fh_next, 0, -s $next;
    }

    my @results;
    my ($linenum, $offset) = (1, 0);
    while($pm =~ /$re/gm) {
      if($+[0] - $-[0] > 1e5) {
         $redis->publish($channel => encode_json {
           error => "Regexp is too greedy"
         });
         return;
      }
      
      # Calculate line number
      my $pos = pos($pm);
      my $fragment = substr($pm, $offset, $pos);
      $linenum++ while ($fragment =~ /\n/g);
      $offset = $pos;

      # XXX: A bit broken in edge cases.
      # Be careful not to use regexps!
      # XXX: may be able to leverage pos() to use regexps
      my $previous = rindex($pm, "\n", $-[0]);
      $previous = 1+rindex($pm, "\n", $previous-1) if $previous > 0;
      my $next = index($pm, "\n", $+[0]);
      $next = index($pm, "\n", 1+$next) if $next > 0;

      # Limit length of snippet, 200 bytes should be enough for anyone
      if($next > $previous + 200) {
        $previous = $previous < $-[0] - 100 ? $-[0] - 100 : $previous;
        $next = $next > $+[0] + 100 ? $+[0] + 100 : $next;
      }
      
      push @results, {
        zset    => $file,
        text    => substr($pm, $previous, $next - $previous),
        snippet => [$previous, $next],
        match   => [$-[0], $+[0]],
        linenum => $linenum,
      };
      
      last if ++$matches > $max;
    }

    $redis->publish($channel => encode_json \@results);

    return if $matches > $max;
  }
}

print "$$: ready\n";

while(1) {
  while(my $item = $redis->blpop("queue:cpangrep:slabsearch", 60)->recv) {
    last unless $item->[0];
    print "$$: processing job: $item->[1]\n";
    my $job = decode_json $item->[1];
    my $slabs = [map $redis->lindex($job->{slablist}, $_)->recv, @{$job->{slabs}}];
    my $max = $job->{max} || 500;
    my $start = time;
    do_match($job->{re}, $max, $job->{notify}, $slabs);
    $redis->publish($job->{notify} => encode_json {
      done => 1,
      id => $job->{id}});
    my $end = time;
    print "$$: job done (", $end-$start, "s)\n";
  }
  $redis->ping->recv;
}

